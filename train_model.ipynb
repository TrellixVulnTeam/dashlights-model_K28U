{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following three cells if you have NOT run data_creation_pipeline.ipynb and need to install them\n",
    "#!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install turicreate skafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y mxnet && pip install mxnet-cu100==1.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Below we do the following:\n",
    "1. Load training data from the sframe `dashlight_images.sframe`. This should have been created by running through the data creation pipeline notebook first.\n",
    "2. Train the object detection model.\n",
    "3. Save the model, testing data, and convert to coreml.\n",
    "4. Evaluate the model against the test data and save the scores.\n",
    "5. Upload to skafos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import turicreate as tc\n",
    "import skafos\n",
    "from skafos import models\n",
    "\n",
    "# Tools for uploading and downloading data and models to S3\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "from utils import s3_upload, s3_download, zip_ext, tarzip_file\n",
    "s3_bucket=\"skafos.dashlights\"\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "FORMAT = \"%m%d%Y%H%M%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download baseline training dataset -- This may vary depending on how we have named training data set\n",
    "sframe_name = \"dashlight_images.sframe\"\n",
    "\n",
    "sframe_name_zipped = sframe_name + zip_ext\n",
    "s3_download(bucket=s3_bucket, filename=sframe_name_zipped, key=\"datasets/sframes/\" + sframe_name_zipped, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with turicreate\n",
    "dataset = tc.load_sframe(sframe_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Save training/testing data folds\n",
    "train_percentage = 0.8\n",
    "train_data, test_data = dataset.random_split(train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL TRAINING ###\n",
    "\n",
    "# Setup GPU for training\n",
    "tc.config.set_num_gpus(-1)\n",
    "tc.config.set_runtime_config('TURI_DEFAULT_NUM_PYLAMBDA_WORKERS', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = tc.object_detector.create(\n",
    "    dataset=train_data,\n",
    "    annotations=\"annotations\",\n",
    "    batch_size=32,\n",
    "    max_iterations=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model artifacts version\n",
    "VERSION = datetime.now().strftime(FORMAT)\n",
    "\n",
    "# Save the model here\n",
    "model_name = VERSION + \"_dashlights_model\"\n",
    "model.save(model_name)\n",
    "\n",
    "#zip dashlights model\n",
    "shutil.make_archive(model_name, 'zip', model_name)\n",
    "zipped_model = model_name + '.zip'\n",
    "\n",
    "# Upload model to s3\n",
    "s3_upload(filename=zipped_model, bucket=s3_bucket, key=\"model-artifacts/\" + VERSION + \"/\" + zipped_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out test data\n",
    "test_file_name = VERSION + \"_testing_sframe\"\n",
    "test_data.save(test_file_name)  # sframe is good for loading and using in turi\n",
    "\n",
    "# create a ZipFile object so we could download the test data too\n",
    "test_file_images = VERSION + '_test_images.zip'\n",
    "zipObj = zipfile.ZipFile(test_file_images, 'w')\n",
    " \n",
    "# Add multiple files to the zip\n",
    "for file in test_data['path']:\n",
    "    zipObj.write(file)\n",
    "    \n",
    "# close the Zip File\n",
    "zipObj.close()\n",
    "\n",
    "#Zip test frame \n",
    "shutil.make_archive(test_file_name, 'zip', test_file_name)\n",
    "test_sframe_zipped = test_file_name + '.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload test_frame + associated images to s3\n",
    "s3_upload(filename=test_sframe_zipped, bucket=s3_bucket, key='testing-data/' + VERSION + \"/\" + test_sframe_zipped)\n",
    "s3_upload(filename=test_file_images, bucket=s3_bucket, key='testing-data/' + VERSION + \"/\" + test_file_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL VALIDATION ###\n",
    "\n",
    "# Get predictions and evaluation metrics\n",
    "scores = model.evaluate(test_data, iou_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get actual predictions and take a look at some model results visually\n",
    "test_data['predictions'] = model.predict(test_data, iou_threshold=0)\n",
    "test_data['images_w_preds'] = tc.object_detector.util.draw_bounding_boxes(test_data['image'], test_data['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through a subset of the predictions and take a look!\n",
    "for i in test_data['images_w_preds'][:10]:\n",
    "    i.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the model scores\n",
    "with open(VERSION + \"_model_scores.json\", \"w\") as f:\n",
    "    f.write(json.dumps(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to coreml + upload artifact to s3\n",
    "model.export_coreml(\"dashlights.mlmodel\", iou_threshold=0)\n",
    "s3_upload(filename=\"dashlights.mlmodel\", bucket=s3_bucket, key='model-artifacts/' + VERSION + \"/\" + \"dashlights.mlmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export with Skafos\n",
    "Use Skafos SDK to upload the model to the dashlights project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get account summary and api token set\n",
    "\n",
    "os.environ[\"SKAFOS_API_TOKEN\"] = \"\"\n",
    "#skafos.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our options\n",
    "opts = {\n",
    "    'org_name': 'skafos-demo',\n",
    "    'app_name': 'DashLights',\n",
    "    'model_name': 'dashlights'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the details of this description before saving\n",
    "desc = \"Version ___: trained on ____ images, final loss ___, image sizes ___, <other notes>\"\n",
    "\n",
    "# Example\n",
    "#Version 08202019182036: trained on ~1000 images, different icon sizes and multiple in frame, final loss 1.05, images 416x416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model\n",
    "res = models.upload_version(\n",
    "    files=\"dashlights.mlmodel\",\n",
    "    description=desc,\n",
    "    **opts\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
